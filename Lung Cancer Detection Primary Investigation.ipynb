{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-radius:10px;\n",
    "            border:#0b0265 solid;\n",
    "           background-color:#0077be;\n",
    "           font-size:110%;\n",
    "           letter-spacing:0.5px;\n",
    "            text-align: center\">\n",
    "\n",
    "<center><h1 style=\"padding: 25px 0px; background color:#0077be; font-weight: bold; font-family: Cursive\">\n",
    "Lung Cancer Detection Primary Investigation</h1></center>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lung Cancer Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the leading causes of death worldwide has been recognised as lung cancer . It is \n",
    "one of the most dangerous tumours that can harm a person. Its death rate ranks among \n",
    "all tumor deaths and is the leading cause of cancer death in both men and women .\n",
    "Lung cancer accounts for 13% of all cancer cases with over 1.8 million new cases and\n",
    "1.6 million deaths annually . A tumour is created when abnormal cells continue to \n",
    "proliferate and grow. Lung cancer has the highest mortality rate compared to other \n",
    "cancer types. Yet individuals have a greater success rate it will be found in the early \n",
    "stages of life. Cancer cells are distributed in blood from the lungs.To Examination and \n",
    "treatment of lung disease has become one of the biggest obstacles that humanity faces \n",
    "in recent years. To overcome this we used convolutional neural Network (CNN) to \n",
    "identify the lung tumors as malignant/benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-15T05:21:54.988356Z",
     "iopub.status.busy": "2023-04-15T05:21:54.987387Z",
     "iopub.status.idle": "2023-04-15T05:22:16.286493Z",
     "shell.execute_reply": "2023-04-15T05:22:16.285423Z"
    },
    "papermill": {
     "duration": 21.308343,
     "end_time": "2023-04-15T05:22:16.289149",
     "exception": false,
     "start_time": "2023-04-15T05:21:54.980806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('\"C:/Users/91812/Downloads/archive\"'):\n",
    "    for filename in filenames:\n",
    "        os.path.join(dirname, filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.004311,
     "end_time": "2023-04-15T05:22:16.298743",
     "exception": false,
     "start_time": "2023-04-15T05:22:16.294432",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Importing Libraries & Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T05:22:16.309740Z",
     "iopub.status.busy": "2023-04-15T05:22:16.308136Z",
     "iopub.status.idle": "2023-04-15T05:22:33.479560Z",
     "shell.execute_reply": "2023-04-15T05:22:33.478335Z"
    },
    "papermill": {
     "duration": 17.179388,
     "end_time": "2023-04-15T05:22:33.482391",
     "exception": false,
     "start_time": "2023-04-15T05:22:16.303003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torchvision import utils as U\n",
    "from torchvision.transforms import transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import torch.optim\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T05:22:33.493589Z",
     "iopub.status.busy": "2023-04-15T05:22:33.492965Z",
     "iopub.status.idle": "2023-04-15T05:22:33.605021Z",
     "shell.execute_reply": "2023-04-15T05:22:33.604022Z"
    },
    "papermill": {
     "duration": 0.119834,
     "end_time": "2023-04-15T05:22:33.607018",
     "exception": false,
     "start_time": "2023-04-15T05:22:33.487184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.004153,
     "end_time": "2023-04-15T05:22:33.615583",
     "exception": false,
     "start_time": "2023-04-15T05:22:33.611430",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Pre-Processing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing images plays a crucial role in the accurate detection of lung cancer. Through a series of preprocessing steps, such as image resizing, normalization, noise reduction, and contrast enhancement, the quality and suitability of the lung images are improved. These preprocessing techniques help in optimizing the images for subsequent analysis and feature extraction, enabling sophisticated algorithms to identify potential abnormalities, nodules, or tumors indicative of lung cancer. The careful application of preprocessing methods enhances the accuracy and reliability of the overall lung cancer detection system, assisting medical professionals in early diagnosis and timely intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T05:22:33.625786Z",
     "iopub.status.busy": "2023-04-15T05:22:33.625190Z",
     "iopub.status.idle": "2023-04-15T05:22:33.631333Z",
     "shell.execute_reply": "2023-04-15T05:22:33.630618Z"
    },
    "papermill": {
     "duration": 0.013361,
     "end_time": "2023-04-15T05:22:33.633220",
     "exception": false,
     "start_time": "2023-04-15T05:22:33.619859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dictionary = {0: 'NORMAL', 1: 'PNEUMONIA'}\n",
    "\n",
    "def map_img(img):\n",
    "    label = img.parent.name\n",
    "    img = Image.open(img).convert('L')\n",
    "    img = img.resize((150, 150))\n",
    "    y = lambda x: torch.tensor(0, device = device) if x == dictionary[0] else torch.tensor(1, device = device)\n",
    "    process = T.Compose([T.ConvertImageDtype(dtype = torch.float32)])\n",
    "    return img, process(y(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T05:22:33.643163Z",
     "iopub.status.busy": "2023-04-15T05:22:33.642902Z",
     "iopub.status.idle": "2023-04-15T05:22:33.647230Z",
     "shell.execute_reply": "2023-04-15T05:22:33.646237Z"
    },
    "papermill": {
     "duration": 0.011643,
     "end_time": "2023-04-15T05:22:33.649167",
     "exception": false,
     "start_time": "2023-04-15T05:22:33.637524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_tensors(path):\n",
    "    return [map_img(img) for folder in path.iterdir() for img in list(folder.iterdir())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T05:22:33.658886Z",
     "iopub.status.busy": "2023-04-15T05:22:33.658460Z",
     "iopub.status.idle": "2023-04-15T05:22:33.663010Z",
     "shell.execute_reply": "2023-04-15T05:22:33.661895Z"
    },
    "papermill": {
     "duration": 0.011791,
     "end_time": "2023-04-15T05:22:33.665181",
     "exception": false,
     "start_time": "2023-04-15T05:22:33.653390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = Path(\"C:/Users/91812/Downloads/archive/chest_xray/test\")\n",
    "val = Path('C:/Users/91812/Downloads/archive/chest_xray/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T05:22:33.675062Z",
     "iopub.status.busy": "2023-04-15T05:22:33.674798Z",
     "iopub.status.idle": "2023-04-15T05:22:54.760155Z",
     "shell.execute_reply": "2023-04-15T05:22:54.759102Z"
    },
    "papermill": {
     "duration": 21.093193,
     "end_time": "2023-04-15T05:22:54.762718",
     "exception": false,
     "start_time": "2023-04-15T05:22:33.669525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ts = load_tensors(test)\n",
    "val_ts = load_tensors(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T05:22:54.773099Z",
     "iopub.status.busy": "2023-04-15T05:22:54.772798Z",
     "iopub.status.idle": "2023-04-15T05:22:54.798869Z",
     "shell.execute_reply": "2023-04-15T05:22:54.797940Z"
    },
    "papermill": {
     "duration": 0.033409,
     "end_time": "2023-04-15T05:22:54.800841",
     "exception": false,
     "start_time": "2023-04-15T05:22:54.767432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "normal_train = 'C:/Users/91812/Downloads/archive/chest_xray/train/NORMAL'\n",
    "pneumonia_train = 'C:/Users/91812/Downloads/archive/chest_xray/train/PNEUMONIA'\n",
    "\n",
    "train_normal = [os.path.join(normal_train, file) for file in os.listdir(normal_train)]\n",
    "train_pneumonia = [os.path.join(pneumonia_train, file) for file in os.listdir(pneumonia_train)]\n",
    "\n",
    "np.random.seed(30)\n",
    "\n",
    "train_normal_sample = np.random.choice(train_normal, size = 1000)\n",
    "train_normal = list(zip(train_normal_sample, np.zeros(1000)))\n",
    "\n",
    "train_pneumonia_sample = np.random.choice(train_pneumonia, size = 1000)\n",
    "train_pneumonia = list(zip(train_pneumonia_sample, np.ones(1000)))\n",
    "\n",
    "train_dataset = train_normal + train_pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T05:22:54.811119Z",
     "iopub.status.busy": "2023-04-15T05:22:54.810599Z",
     "iopub.status.idle": "2023-04-15T05:23:53.645857Z",
     "shell.execute_reply": "2023-04-15T05:23:53.644806Z"
    },
    "papermill": {
     "duration": 58.843273,
     "end_time": "2023-04-15T05:23:53.648834",
     "exception": false,
     "start_time": "2023-04-15T05:22:54.805561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def map_train(item):\n",
    "    image, label = item\n",
    "    image = Image.open(image).convert('L')\n",
    "    image = image.resize((150, 150))\n",
    "    label = torch.tensor(label, device = device)\n",
    "    process = T.Compose([T.ConvertImageDtype(dtype = torch.float32)])\n",
    "    return image, process(label)\n",
    "\n",
    "train_ts = [map_train(item) for item in train_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T05:23:53.659360Z",
     "iopub.status.busy": "2023-04-15T05:23:53.658754Z",
     "iopub.status.idle": "2023-04-15T05:23:59.522340Z",
     "shell.execute_reply": "2023-04-15T05:23:59.521284Z"
    },
    "papermill": {
     "duration": 5.871846,
     "end_time": "2023-04-15T05:23:59.525328",
     "exception": false,
     "start_time": "2023-04-15T05:23:53.653482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = T.Compose([T.PILToTensor(),T.ConvertImageDtype(dtype = torch.float32), T.RandomRotation(20), T. RandomAffine(10)])\n",
    "\n",
    "\n",
    "x_train = torch.cat([transform(t[0]).unsqueeze(1) for t in train_ts])\n",
    "y_train = torch.cat([t[1].unsqueeze(0).unsqueeze(1) for t in train_ts])\n",
    "\n",
    "x_test = torch.cat([transform(t[0]).unsqueeze(1) for t in test_ts])\n",
    "y_test = torch.cat([t[1].unsqueeze(0).unsqueeze(1) for t in test_ts])\n",
    "\n",
    "x_valid = torch.cat([transform(t[0]).unsqueeze(1) for t in val_ts])\n",
    "y_valid = torch.cat([t[1].unsqueeze(0).unsqueeze(1) for t in val_ts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T05:23:59.536787Z",
     "iopub.status.busy": "2023-04-15T05:23:59.536452Z",
     "iopub.status.idle": "2023-04-15T05:23:59.546128Z",
     "shell.execute_reply": "2023-04-15T05:23:59.545230Z"
    },
    "papermill": {
     "duration": 0.017684,
     "end_time": "2023-04-15T05:23:59.548435",
     "exception": false,
     "start_time": "2023-04-15T05:23:59.530751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = tuple(zip(x_train, y_train))\n",
    "test = tuple(zip(x_test, y_test))\n",
    "valid = tuple(zip(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.003915,
     "end_time": "2023-04-15T05:23:59.556556",
     "exception": false,
     "start_time": "2023-04-15T05:23:59.552641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading the DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T05:23:59.566162Z",
     "iopub.status.busy": "2023-04-15T05:23:59.565891Z",
     "iopub.status.idle": "2023-04-15T05:23:59.572196Z",
     "shell.execute_reply": "2023-04-15T05:23:59.571324Z"
    },
    "papermill": {
     "duration": 0.013497,
     "end_time": "2023-04-15T05:23:59.574290",
     "exception": false,
     "start_time": "2023-04-15T05:23:59.560793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train, batch_size = 100, shuffle = True)\n",
    "test_dl = DataLoader(test, batch_size = 100, shuffle = True)\n",
    "val_dl = DataLoader(valid, batch_size = 100, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.003962,
     "end_time": "2023-04-15T05:23:59.582332",
     "exception": false,
     "start_time": "2023-04-15T05:23:59.578370",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining the Convolutional Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T05:23:59.591852Z",
     "iopub.status.busy": "2023-04-15T05:23:59.591547Z",
     "iopub.status.idle": "2023-04-15T05:23:59.601833Z",
     "shell.execute_reply": "2023-04-15T05:23:59.600820Z"
    },
    "papermill": {
     "duration": 0.017467,
     "end_time": "2023-04-15T05:23:59.603895",
     "exception": false,
     "start_time": "2023-04-15T05:23:59.586428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.conv1 = self.conv(1, 32)\n",
    "        self.conv2 = self.conv(32, 64, dropout = True)\n",
    "        self.conv3 = self.conv(64, 64)\n",
    "        self.conv4 = self.conv(64, 128, dropout = True)\n",
    "        self.conv5 = self.conv(128, 256, dropout = True)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.flt = nn.Flatten(start_dim = 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.fc1 = nn.Linear(4096, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1)\n",
    "\n",
    "\n",
    "    def conv(self, in_channels, out_channels, stride = 1, dropout = False):\n",
    "        layers = [nn.Conv2d(in_channels, out_channels, (3, 3), stride = stride, padding = (1, 1)), nn.ReLU()]\n",
    "        if dropout == True:\n",
    "            layers.append(nn.Dropout(0.1))\n",
    "        layers.append(nn.BatchNorm2d(out_channels))\n",
    "        layers.append(nn.MaxPool2d((2,2), stride = 2))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.flt(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T05:23:59.614172Z",
     "iopub.status.busy": "2023-04-15T05:23:59.613905Z",
     "iopub.status.idle": "2023-04-15T05:23:59.667885Z",
     "shell.execute_reply": "2023-04-15T05:23:59.666996Z"
    },
    "papermill": {
     "duration": 0.061245,
     "end_time": "2023-04-15T05:23:59.670096",
     "exception": false,
     "start_time": "2023-04-15T05:23:59.608851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork()\n",
    "model.to(device)\n",
    "\n",
    "optimise = torch.optim.Adam(model.parameters(), lr = 1e-4, weight_decay = 0.01)\n",
    "\n",
    "\n",
    "l = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-15T05:23:59.679808Z",
     "iopub.status.busy": "2023-04-15T05:23:59.679283Z",
     "iopub.status.idle": "2023-04-15T05:23:59.689214Z",
     "shell.execute_reply": "2023-04-15T05:23:59.688368Z"
    },
    "papermill": {
     "duration": 0.017096,
     "end_time": "2023-04-15T05:23:59.691357",
     "exception": false,
     "start_time": "2023-04-15T05:23:59.674261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(epochs):\n",
    "    training_loss = []\n",
    "    training_accuracy = []\n",
    "    test_loss = []\n",
    "    test_accuracy = []\n",
    "    \n",
    "    # train\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        for batch in tqdm(train_dl):\n",
    "            img, labels = batch\n",
    "            img = img.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimise.zero_grad()\n",
    "            \n",
    "            preds = model(img)\n",
    "            loss = l(preds, labels)\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimise.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            accuracy = (preds>0.5).float() == labels.float()\n",
    "            accuracy = accuracy.float().mean()\n",
    "            epoch_accuracy += accuracy.item()\n",
    "                                \n",
    "        \n",
    "        model.eval()\n",
    "        img, labels = next(iter(test_dl))\n",
    "        img = img.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = model(img)\n",
    "        eval_loss = l(preds, labels)\n",
    "\n",
    "        eval_accuracy = (preds>0.5).float() == labels.float()\n",
    "        eval_accuracy = accuracy.float().mean().item()    \n",
    "                \n",
    "        training_loss.append(epoch_loss)\n",
    "        training_accuracy.append(epoch_accuracy)\n",
    "        test_loss.append(eval_loss.item())\n",
    "        test_accuracy.append(eval_accuracy)\n",
    "        \n",
    "        print(f\"Epoch: {i+1}\\t Training Loss: {epoch_loss/len(train_dl)}\\t Training Accuracy: {epoch_accuracy/len(train_dl)}\\nTest Loss: {eval_loss}, \\tAccuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:44<00:00,  5.21s/it]\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\t Training Loss: 0.3048105966299772\t Training Accuracy: 0.8644999966025353\n",
      "Test Loss: 3.579519748687744, \tAccuracy: 0.8999999761581421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:48<00:00,  5.43s/it]\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\t Training Loss: 0.1493612129241228\t Training Accuracy: 0.9435000032186508\n",
      "Test Loss: 5.083327770233154, \tAccuracy: 0.9300000071525574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:48<00:00,  5.43s/it]\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\t Training Loss: 0.11020331010222435\t Training Accuracy: 0.959500002861023\n",
      "Test Loss: 4.252012729644775, \tAccuracy: 0.9599999785423279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:47<00:00,  5.37s/it]\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\t Training Loss: 0.08108987398445607\t Training Accuracy: 0.9700000077486038\n",
      "Test Loss: 5.047478199005127, \tAccuracy: 0.9900000095367432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [01:46<00:00,  5.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\t Training Loss: 0.05446241702884436\t Training Accuracy: 0.9840000122785568\n",
      "Test Loss: 3.997859001159668, \tAccuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "run(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 172.764327,
   "end_time": "2023-04-15T05:24:35.280488",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-15T05:21:42.516161",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
